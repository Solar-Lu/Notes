### 🎯 案例：用 ResNet50 模型在 ImageNet 上找 bug

#### 1️⃣ 准备阶段：拿到“成品模型”
- **模型**：ResNet50（已经在 ImageNet 上训练好，权重固定）。
- **数据**：从 ImageNet 验证集里随机抽 5,000 张图片。
- **后端**：TensorFlow、CNTK、Theano（三个“生产线”）。

> 注意：CRADLE **不训练模型**，只拿现成的模型做“质检”。

---

#### 2️⃣ 发现异常：让模型在三条生产线上“跑一遍”
- **目标**：同一批图片，同一份权重，三个后端分别跑前向传播（推理）。
- **输出**：每张图片会得到一个 1,000 维的置信度向量（比如 [0.7, 0.1, 0.05, ...]）。

#### 🔍 关键步骤：如何判断“异常”？
- **例子**：某张“大象”图片
  - TensorFlow 输出：大象（第 1 位，置信度 0.9）。
  - CNTK 输出：大象被挤到第 6 位，前 5 名全是错的标签。
  - **Class-based 距离**：从 16（最大差异）降到 0（完全一致），这里差异为 16。
  - **结论**：这张图片触发“跨后端不一致”。

- **批量统计**：如果 5,000 张图片里有超过 0% 的图片出现类似差异，标记 ResNet50 在 TF-vs-CNTK 上存在“可疑 bug”。

---

#### 3️⃣ 定位元凶：追踪“异常从哪一层开始”
- **记录中间层输出**：从输入层到输出层，ResNet50 有 50 多层，每层都会输出一个特征图（hidden state）。
- **构建“差异链”**：
  - 逐层计算 TensorFlow 和 CNTK 输出的差异（用 MAD 距离）。
  - **例子**：
    - 第 1-10 层差异很小（0.0001）。
    - 第 11 层（BatchNormalization）差异突然放大到 0.5。
    - 后续层差异继续放大，最终影响分类结果。
- **计算“异常引入率”（RL）**：
  - 第 11 层的 RL 值远高于其他层（比如 0.8 vs 0.01）。
  - **结论**：BatchNormalization 函数在 CNTK 后端是“元凶”。

---

#### 4️⃣ 验证与修复
- **人工检查 CNTK 代码**：发现 BatchNormalization 的公式里漏了 `epsilon`，导致方差计算错误。
- **开发者修复**：在 Keras 2.2.1 中补上 `epsilon`，重新测试后差异消失。

---

### 🧑‍🏫 总结成一句话
**CRADLE 的训练流程就像让同一个“优秀毕业生”（预训练模型）去三家“公司”（后端）实习，如果发现它在这三家公司的表现差异巨大，就倒查是哪一家公司的“培训流程”（后端函数）出了问题。**