**「Hidden Capability Extraction（CapAnalysis）」**

---

## 📌 1. 本节目的
> **回答一个问题**：  
> “**在 1,083 个持久 API 中，到底哪些可以被滥用来读取文件、发送网络包、执行代码？**”  
> 由于**人工审阅上万行跨语言代码不可行**，作者提出 **CapAnalysis** ——**用大型语言模型（LLM）自动挖掘 API 的隐藏能力**。

---

## 🧩 2. 技术挑战
| 挑战 | 具体表现 |
|------|----------|
| **规模巨大** | 1,083 个 API，涉及 Python 声明 + C++ 实现 + 宏嵌套。 |
| **文档缺失/误导** | 官方文档只写“数学计算”，实际代码里却读写文件或联网。 |
| **跨语言链路复杂** | Python → C++ → 宏 → 继承 → 多态，传统静态分析难以追踪。 |

---

## ⚙️ 3. CapAnalysis 三步流程（见下图）

```
┌──────────────┐   ┌──────────────┐   ┌──────────────┐
│ ① 能力分类    │ → │ ② LLM 分析   │ → │ ③ 结果验证    │
└──────────────┘   └──────────────┘   └──────────────┘
```

### ✅ Step 1：建立能力分类体系（人工+LLM 迭代）
- **首轮手动抽样 100 个 API** → 粗粒度 4 类  
- **两轮 ChatGPT-4 迭代** → 细粒度 **5 大类 13 小类**：

| 大类 | 小类示例 |
|------|----------|
| **文件访问** | 读、写、目录遍历 |
| **网络通信** | 发送、接收 |
| **代码执行** | 动态函数、脚本 |
| **进程管理** | 创建、终止 |
| **纯计算** | 数学、数据管理 |

### ✅ Step 2：LLM 三阶段链式分析
| 阶段 | LLM 任务 | 示例输入片段 | 输出 |
|------|----------|--------------|------|
| **① 注释分析** | 从 docstring/参数描述提取线索 | `debug_urls: gRPC server address` | 推断“有网络发送能力” |
| **② 宏分析** | 解析 OP_REQUIRES/AppendStringToFile 等宏 | `AppendStringToFile(file_path_,...)` | 推断“可写文件” |
| **③ 逻辑分析** | 阅读 `Compute()` 实现 | `NewReadOnlyMemoryRegionFromFile(...)` | 推断“可读取任意文件” |

- **Prompt 设计**：  
  采用 **XML 结构化 prompt**，含任务描述、三步骤示例、JSON 输出模板，确保一致性与可解析性。

### ✅ Step 3：两轮问答 + 人工校验
- **第一轮**：LLM 先自由报告能力 → 发现遗漏 → 完善分类。  
- **第二轮**：用细化分类再跑一遍 → **准确率从 70% 提升到 83%**。  
- **人工验证**：随机 100 个 API 手工标 ground-truth，用于评估与校正。

---

## 📊 4. 结果总览（v2.15）
| 能力类别 | API 数量（Round2） | 典型例子 |
|----------|--------------------|----------|
| 纯计算   | 965                | `MatMul`, `Conv2D` |
| 文件访问 | 58                 | `ReadFile`, `WriteFile`, `MatchingFiles` |
| 网络通信 | 25                 | `DebugIdentityV3`, `rpc_client` |
| 代码执行 | 54                 | `PyFunc`, 自定义 op |
| 进程管理 | 13                 | `SpawnProcess` |

---

## ⚠️ 5. 误差来源与改进
| 原因 | 占比 | 举例 |
|------|------|------|
| 注释/函数名误导 | 9/17 | `CreateSummaryDbWriter` 看似写 DB，实际只创建资源 |
| 深层调用链 & 多态 | 10/17 | `GatherCollective` 经过三层虚函数，CodeQL 漏掉后续调用 |
| LLM 幻觉 | 4/17 | 误认为 `CacheDataset` 会落盘 |

---

## ✅ 6. 性能与成本
- **token 消耗**：每轮约 **90 美元**（ChatGPT-4）。  
- **时间**：两轮 ≈ 2 小时 vs 人工数周。  
- **可扩展**：可替换为 Llama3-405B 等开源模型降低成本。

---

## 🎯 7. 一句话总结
> CapAnalysis 通过 **“人工分类 + LLM 链式分析 + 人工校验”** 的三级流水线，**首次系统性地挖掘出 1,083 个 TensorFlow 持久 API 中可被滥用的 118 个隐藏能力**，为后续构造 TensorAbuse 攻击提供了精准的“武器库”。